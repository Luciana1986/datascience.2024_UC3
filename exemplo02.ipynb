{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtendo dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "try:\n",
    "    print('Obtendo dados...')\n",
    "\n",
    "ENDERECO_DADOS = 'https://raw.githubusercontent.com/americanas-tech/b2w-reviews01/refs/heads/main/B2W-Reviews01.csv'\n",
    "\n",
    "df = pd.read_csv(ENDERECO_DADOS, sep= ',', encoding='utf-8')[['review_title', 'overall_rating']]\n",
    "                                                            \n",
    "df = df.dropna(subset=['review_title','overall_ratting'])    \n",
    "\n",
    "# excluindo dados não existentes (NaN)\\n\",\n",
    "df = df.dropna(subset=['review_title','overall_rating'])\n",
    "\n",
    "#Tranformando colunas em arrays,\n",
    "texts = np.array(df['review_title'])\n",
    "rating = np.array(df['overall_rating'])\n",
    "\n",
    "print(df.head())\n",
    "    \n",
    "    except Exception as e:\n",
    "    print('Erro ao obter dados:',e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vetorização**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para trabalhar com redes neurais artificiais\n",
    "#Tensorflow - https://www.tensorflow.org/?hl=pt-br# Tokenizar\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "    # ajustar o tamanho do vetor\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "\n",
    "try:\n",
    "    print('Vetorizando texto...')\n",
    "    \n",
    "    # Passo 1: tokenizar\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    # Passo 2: Criar o dicionário\\n\",\n",
    "    # fit_on_texts: Cria o vocabulário, através do dicionário\\n\",\n",
    "    # associando cada token a um índice numérico\\n\",\n",
    "    # lembrando que se a palavra aparecer mais de uma vez, ela vai receber o mesmo índice numérico\\n\",\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "\n",
    "    # Passo 3: Vetorizar, ou seja, transformar os tokens em números,\\n\",\n",
    "    # a partir do dicionário criado no passo 2\n",
    "    vetores = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    # Passo4: Padronização do tamanho do vetor - pad\\n\",\n",
    "    padded_vetores = pad_sequences(vetores)\n",
    "    \n",
    "    print(padded_vetores)\n",
    "   \n",
    "    print('Textos vetorizados!')\n",
    " \n",
    "except Exception as e:\n",
    "        print('Erro ao vetorizar textos: ', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rede Neural**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do modelo de rede neural utilizada\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "# Camadas da rede neural\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # type: ignore\n",
    "\n",
    "\n",
    "try:\n",
    "    print('Construindo a rede neural')\n",
    "\n",
    "# Constante do modelo\n",
    "# 1ª constante: tamanho do vocabulário\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1     \n",
    "\n",
    "# 2ª constante: tamanho máximo da sequência\n",
    "# é o comprimento máximo de um texto\n",
    "\n",
    "MAX_SEQUENCE_LENGHT = padded_vetores.shape[1]\n",
    "\n",
    "# 3ª constante: tamanho do vetor de entrada\n",
    "# A literatura recomenda que inicia-se por uma quantidade igual a raiz quadrada do tamanho do vocabulário\n",
    "# se o volume de dados for de larga escala, pode testar iniciando com um tamanho maior\n",
    "# se o volume de dados for muito pequeno, pode-se testar iniciando com um tamanho menor\n",
    "# Cuidado com o overfitting, que é quando o modelo aprende demais e começa a perde a capacidade de generalizar melhor, ou seja, observar todas as diferenças textuais\n",
    "# Overfitting pode ser observado no treino da rede neural\n",
    "\n",
    "VETOR_LENGHT = int(np.sqrt(VOCAB_SIZE))\n",
    "\n",
    "# inicia-se a construção da rede neural\n",
    "# sequential é um fluxo linear de camadas( conforme visto na aula 02 RNA.pptx)\n",
    "# são processadas em ordem\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# camada de entrada\n",
    "# Embedding, na qual os vetores de texto são inseridos\n",
    "\n",
    "model.add(Embedding(input_dim= VOCAB_SIZE,output_dim=VETOR_LENGHT, input_lenght = MAX_SEQUENCE_LENGHT))\n",
    "                \n",
    "# Camada oculta ou intermediária\n",
    "# LSTM - long short-term memory, em portugues é \"memória de longo e curto prazo\"\n",
    "# é onde a magia acontece, ou seja, onde o modelo treina baseado nos seus vetores\n",
    "# números de unidades de memória, que basicamente é a quantidade de neurônios\n",
    "# primeiro TESTE, experimente somente com uma camada! cuidado com overfitting!\n",
    "# se for necessário adcionar mais camadas basta adicionar repetir o comando abaixo\n",
    "\n",
    "# primeira camada oculta\n",
    "\n",
    "model.add(LSTM(128))\n",
    "\n",
    "# se é necessário adicionar outra camada oculta\n",
    "# model.add(LSTM(64))\n",
    "\n",
    "# camada de saida que é a camada densa\n",
    "# regressão que é o caso desse exemplo. Somente 1 camada\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "# construir o modelo\n",
    "# é literalmente pegar as definições anteriores e construir o modelo\n",
    "# input_shape: é p formato do dados de entrada e ainda o tamanho maximo do meu texto(MAX_SEQUENCE_LENGHT)\n",
    "\n",
    "model.build(input_shape= (None,MAX_SEQUENCE_LENGHT))\n",
    "\n",
    "# otimizador de taxa de aprendizado\n",
    "# importante para ajustar, em casos de overfitting\n",
    "# Adam: é nosso otimizador que vai ajustar essa taxa de aprendizado\n",
    "# learning_rate: quanto menor\n",
    "\n",
    "\n",
    "# Otimizador de taxa de aprendizado\\n\",\n",
    "# importante para ajustar, em casos de overfitting\\n\",\n",
    "# Adam: É nosso otimizador que vaia ajustar essa taxa de aprendizado\\n\",\n",
    "# learning_rate: Quanto menor, melhor o aprendizado. Menos risco de overfitting\\n\",\n",
    "otimizador = Adam(learning_rate=0.0005)\n",
    "   \n",
    "# compilar o modelo\\n\",\n",
    "# Verificar se possui algum erro ou se tá de boa\\n\",\n",
    "# Além disso, vamos informar o otimizador e a nossa métrica de perda (loss)\\n\",\n",
    "# loss - Erro quadrado médio (mean_squared_error)\\n\",\n",
    "model.compile(optimizer=otimizador, loss='mean_squared_error')\n",
    "\n",
    "model.summary()\n",
    "print('Modelo configurado e criado')\n",
    "   \n",
    "\n",
    "except Exception as e:\n",
    "    print('Erro ao construir a rede neural', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLICAR MELHOR NA PRÓXIMA AULA\\n\",\n",
    "from sklearn.model_selection import train_test_split\n",
    "   \n",
    "try:\n",
    "        print('Treinar o modelo de rede neural')\n",
    "   \n",
    "X_train, X_test, y_train, y_test =train_test_split(padded_vetores,rating,test_size=0.2, random_state=42)\n",
    "    \n",
    "# o treino da rede neural\\n\",\n",
    "model.fit (X_train,y_train,epochs=5,batch_size=128,validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "       print('Erro ao treinar a rede neural: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_textos = ['Muito bom gostei bastante. Top demmais! compensa muito!','Não recomendo, péssimo produto. Não funciona']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
